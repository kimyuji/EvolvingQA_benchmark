{
    "input_length" : 512,
    "output_length" : 512,
    "num_train_epochs" : 1,
    "output_dir" : "outputs/diff_03_lora",
    "dataset" : "wikipedia_0203_gpt2",
    "dataset_version" : "full",
    "train_batch_size" : 8,
    "learning_rate" : 1e-4,
    "model" : "gpt2-large",
    "method": "lora",
    "gradient_accumulation_steps" : 1,
    "ngpu" : 1,
    "num_workers" : 40,
    "resume_from_checkpoint" : null,
    "accelerator" : "ddp",
    "fp16" : true,
    "CUDA_VISIBLE_DEVICES" : "0,1",
    "wandb_log": true,
    "wandb_project": "continual_lm",
    "wandb_run_name" : "diff_03_lora",
    "mode" : "pretrain",
    "use_lr_scheduling" : true,
    "check_validation" : false,
    "checkpoint_path" : "outputs/pretrained_02_epoch=2"
}
